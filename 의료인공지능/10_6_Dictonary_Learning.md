# 10.6. Dictonary Learning

![스크린샷 2025-06-18 18.45.34.png](/assets/의료인공지능/10_6_Dictonary_Learning/스크린샷_2025-06-18_18.45.34.png)

직전 챕터에서는 딕셔너리는 고정되었고, alpha값만 찾아야 했었는데, 이번엔 딕셔너리에 대한 값도 찾아야하는 어려움에 도달

다음과 같은 방법으로 해결 해 볼 수 있음.

1. Initialize Dictionary
    - 아무 딕셔너리를 초기화 값으로 사용
2. Repeat
    1. Sparse Coding
        - 딕셔너리가 고정되어있다고 하면 Sparse equation. L1 norm 텀을 풀어서 딕셔너리값과 alpha 값을 구할 수 있음
    2. Codebook Update using K-SVD
        - D값과 alpha 값을 구하게 되면 코드부 업데이트라는걸 통해 D값과 alpha값을 같이 업데이트하는데, K-SVD기법을 사용 할 수 있습니다.
        
        ![스크린샷 2025-06-18 19.30.34.png](/assets/의료인공지능/10_6_Dictonary_Learning/스크린샷_2025-06-18_19.30.34.png)
        
        > K-SVD : dictionary의 각 column(원자)을 하나씩 순회하며, 해당 원자가 기여하는 Residual을 계산한뒤, 이를 SVD로 분해하여 해당 웑(D_K)와 관련된 sparse coefficietn(a_k)를 함께 업데이트합니다. 즉, 순차적으로 딕셔너리와, 딕셔너리 순번과 일치하는 알파 값들을 업데이트.
        예시로, 딕셔너리의 4번째 행을 업데이트 한다고하면, 알파4 라인이 업데이트됨.. 이후 다른 딕셔너리들을 순회하며 업데이터 ~~
        > 
        - 만약, 네 번째 딕셔너리, 알파가 없더라도, m-1로 처리하여 업데이트 할 수 있씁니다. 하지만, 특정 컬럼, 특정 로우가 없더라도 실제 벡터의 매트릭스 곱을 해보면 똑같이 n, k를 문제 없이 구할 수 있어 메트릭스를 완벽하게 복원하기가 어렵긴 하나, 복원이 가능합니다.
            
            ![스크린샷 2025-06-18 19.46.38.png](/assets/의료인공지능/10_6_Dictonary_Learning/스크린샷_2025-06-18_19.46.38.png)
            

![스크린샷 2025-06-18 19.54.41.png](/assets/의료인공지능/10_6_Dictonary_Learning/스크린샷_2025-06-18_19.54.41.png)

1. 옵져베이션 했던 Y를 X와 비교했을때 완벽하진 않지만 어느정도 비슷하게 만들수 있고,
2. y-x를 통해 residual(차이)를 구할수 있습니다. 해당 차이를 잘 복원해줄 딕셔너리를 만들 수 있다면 좋은 상황이 되겠습니다. 

딕셔너리를 통해 R(residual) 복원하기 위해 SVD(singular value decomposition)를 사용합니다.

# K-SVD

최상단 좌측)어떠한 NxM크기의 메트릭스가 있다고 가정하고(R), SVD를 적용하면 3개의 매트릭스를 얻을 수 있습니다.

![스크린샷 2025-06-18 21.56.56.png](/assets/의료인공지능/10_6_Dictonary_Learning/스크린샷_2025-06-18_21.56.56.png)

아래 3개의 메트릭스의 곱으로 R의 메트릭스를 얻을 수 있다.

1. NxM함수(nxn) : U로 표현
2. eigenvalue matrix(nxm) : alpha(1) ~ alpha(s)
3. matrix(nxm) : vT(ttransfpose)

***(* 빗금 영역은 버려지는 영역(상위 r개의 특이값만 유지하지하는것→ 노이즈 제거 및 정보 압축의 목적). 즉, 해상도를 낮춰 핵심 성분만 사용하고(상위 r개의 중요한 성분남기기) 추후 복원)***

![스크린샷 2025-06-18 22.05.15.png](/assets/의료인공지능/10_6_Dictonary_Learning/스크린샷_2025-06-18_22.05.15.png)

이러한 모습으로 빗금 영역을 지워 주요 성분만 남기게 되었습니다.

![스크린샷 2025-06-18 22.10.38.png](/assets/의료인공지능/10_6_Dictonary_Learning/스크린샷_2025-06-18_22.10.38.png)

또한, 추가적으로 2번째 matrix에서 alpha(1) ~ alpha(s)의 앞부분이 주요한 정보가 많기에, 뒤쪽 alpha부분을 제거하게 되면 1번 메트릭스, 2번 메트릭스, 3번 메트릭스에 대해서 ***더 영역을 줄일 수 있습니다.***

                                                                  1R = 2R, 1R ≠ 3R.              

 2번째R에서 추가적으로 alpah값들을 제거했기 때문입니다.

![스크린샷 2025-06-18 22.12.55.png](/assets/의료인공지능/10_6_Dictonary_Learning/스크린샷_2025-06-18_22.12.55.png)

3R. 3개의 matrix의 앞쪽 row의 성분들이 R의 복원에서 중요한 성분이 되겠습니다.

### 그래서,,  3R에서의 1번째 matrix를 D. 2번,3번matrix를 alpha로두고, 업데이트를 하겠다. → K-SVD

![스크린샷 2025-06-18 22.16.30.png](/assets/의료인공지능/10_6_Dictonary_Learning/스크린샷_2025-06-18_22.16.30.png)

> K-SVD 핵심 아이디어
1. residual 행렬에 대해 SVD 적용
2. 특이값 중 상위 r개만 선택하여 중요 정보만 남기고 압축
3. 버려지는 성분(빗금 영역)은 노이즈나 저정보량으로 간주
4. SVD로 얻어진 성분들로 dictionary와 coefficient를 동시에 업데이트
> 

> 목적 및 효과
1. 관측 데이터 Y를 dictionary와 sparse vector의 곱으로 잘 근사하고자 함
2. SVD 기반 dictionary 업데이트로, 표현력 있는 딕셔너리 자동 생성 가능
3. 노이즈 억제, 데이터 압축, 해석 가능성 모두 개선
>