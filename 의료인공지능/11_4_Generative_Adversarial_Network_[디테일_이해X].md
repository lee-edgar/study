# 11.4. Generative Adversarial Network [디테일 이해X]

![스크린샷 2025-06-23 17.39.45.png](/assets/의료인공지능/11_4_Generative_Adversarial_Network_[디테일_이해X]/스크린샷_2025-06-23_17.39.45.png)

1. Generator(생성자, 하단부)
    - “진짜 같은 가짜”를 만드는 역할
    - 노이즈한(랜덤한 벡터)를 받아 이미지를 생성
2. Discriminator(판별자, 상단부)
    - “진짜 vs. 가짜”를 구분하는 역할
    - 생성자가 만든 이미지와 실제 이미지를 보고 진위를 판단

이 둘이 서로 겨루면서(Adversarial)

- 생성자는 판별자를 속이기 위해 점점 더 그럴듯한 이미지를 만들고
- 판별자는 생성자가 만든 가짜를 점점 더 잘 골라내도록 학습합니다.

### 학습 과정

1. 판별자 업데이트
    - 실제 이미지 → “진짜”
    - 생성자 출력 이미지 → “가짜”
    - 두 입력의 판단 결과 오류를 줄이는 방향으로 학습
2. 생성자 업데이트
    - 생성자가 만든 이미지를 판별자를 보여주고,
    - 판별자가 진짜로 잘못 판단하도록 생성자의 파라미터 조정

위 과정을 번갈아 반복하며,

- 판별자는 “진짜와 가짜 차이”를 더 잘 민감하게 측정하고
- 생성자는 “진짜처럼 보이는” 고품질 이미지를 생성하게 됩니다.

### 왜 강력한가 ?

- 데이터 분포 학습 : 실제 샘플 분포를 직접 모델링 하지 않아도, 판별자와 경쟁하면서 자연스럽게 학습함
- 고해상, 고품질 샘플 : 전통적 생성 모델보다 “디테일”이 뛰어난 결과를 보임.

### 슈퍼해상도에서 GAN(SRGAN)

- Preceptual Loss : 픽셀 오차(L2) 대신, VGG 같은 네트워크의 특징 맵 차이로 “사람 눈에 더 자연스러운” 결과 얻기
- Adversarial Loss : GAN 손실을 추가해 질감, 디테일을 살리고
- 결과 : PSNR 보다 SSIM 주관적 화질에서 눈에 띄는 개선

> GAN은 가짜 이미지를 만들고, 진짜와 구분하는 인공지능이 서로 경쟁하며 발전하는 모델임. 이 적대적 학습 덕분에 매우 사실적인 이미지를 생성합니다.
의료 인공지능에서는 데이터가 부족하거나, 노이즈, 도메인 차이가 큰 상황을 극복하기 위한 가짜 데이터 생성, 모달리티 변환, 화질 개선, 이상 검출 툴킷 등으로 자리잡았습니다만, 실제 임상을 위해 합성 정확성, 안전성 검증, 규제 준수가 반드시 뒷받침이 필요합니다.\
> 

의료 인공지능에서의 GAN 케이스

1. 데이터 증강
    
    (예시) 뇌 MRI 데이터가 적은 소아 환자군에서 병변을 합성해 종양 검출 네트워크 학습률 ⬆️
    
    1. 희귀 질환 병변 생성
        - 실제 환자 수가 적어 학습 예시가 부족한 병변
    2. 다양한 해부학적 변이 생성
        - 연령, 성별, 인종별 차이 반영하여 다양한 환자군 이미지 생성
2. 영상 간 변환 합성
    
    (예시) CycleGAN을 써서 T1, T2 MRI 간 합성, 다중 모델 데이터 불일치 해소
    
    1. MRI ↔ CT 변환(CycleGAN)
        - 방사선 피폭이 없는 MRI로 C처럼 골 구조 측정
    2. 저선량 CT → 표준선량 CT(cGAN)
        - 방사선을 줄여 얻은 노이즈 많은 CT를 GAN으로 복원
3. 노이즈 제거, 초해상도
    
    (예시) SRGAN으로 심장 MRI 해상도 2배 ⬆️, 영상 검출 지표(SSIM, PSNR) 크게 개선
    
    1. 초해상도 SRGAN
    2. GAN 기반 Denoising
        - 저용량 PET. 초음파 영상의 잡음 성분 제거
4. 이상 검출
    
    (예시) 폐 결절 분할에서 GAN 판별자가 더 세밀한 경계 학습을 유도해 Dice 계수 ⬆️
    
    1. Anomaly GAN(f-AnoGAN)
        - 정상 조직만 학습한 GAN에서 재구성 오차를 기반으로 이상(병변) 픽셀 검출
    2. Adversarial Segmentation
        - U-Net + PatchGAN구조로, 예측한 마스크가 실제 레이블처럼 보이도록 훈련

# Conditional GAN, cGAN

![스크린샷 2025-06-23 20.01.28.png](/assets/의료인공지능/11_4_Generative_Adversarial_Network_[디테일_이해X]/스크린샷_2025-06-23_20.01.28.png)

Pix2Pix라고 알려진 Conditional Gan(cGAN)은 스케치 ↔실제 사진 같은 쌍(pair)이 있는 데이터를 한 세트로 묶어 학습합니다.

- sketch ↔ real photo
- [ image ↔ segmentation label ] → training .. segmentation map

어떤 X를 generator(G)에 넣는 다고 가정하면, generator가 X에 대응하는 출력 생성합니다. 

- 예를 들어, X가 스케치 영상이라면, G(x)는 입력된 스케치와 비슷한 리얼 영상을 합성해 냅니다.

그 다음, 생성된 리얼 포토와 원본 입력 X의 쌍을 Discriminator에 함꼐 넣어서 “이 쌍이 진짜(real)인지, 가짜(fake)인지 ” 판별하게 됩니다. 

- Discriminator는 진짜 쌍(X,Y)에 대해서는 1에 가깝게, 가짜 쌍(X, G(X))에 대해서는 0에 가깝게 출력하도록 학습합니다.
- 동시에 Generator는 Discriminator를 속여 D(X, G(X))가 1을 출력하도록 반복해서 업데이트 합니다.

위 과정을 통해 G와 D가 번갈아가면서 경쟁적으로 발전하면서, 최종적으로는 스케치만으로 실제처럼 보이는 사진 또는 레이블만 보고 실제 segmentation map을 생성 할 수 있게 되는 것이 cGAN의 핵심이 되겠습니다.

# CycleGAN

1번 화가의 이미지를 2번 화가의 이미지로 변환하는지 등

“쌍(pair)이 없는 이미지간 번역을 가능하게 해주는 모델로, 예컨대 서로 대응되는 사진-스케치 쌍이 없더라도 “스케치만 보고 사진을”, “사진만 보고 스케치를” 모두 학습 할 수 있도록 설계되었습니다.

이때, CycleGAN은 두 개의 Generator G와 F를 사용합니다. G는 도메인 X의 이미지를 도메인 Y스타일로 변환하고, F는 도메인 Y 이미지를 도메인 X 스타일로 되돌립니다. 예컨대, G에 스케치를 넣으면 “스케치 → 사진”이 F에 사진을 넣으면 “사진 → 스케치”가 생성되는 식입니다. 여기서의 핵십은 Cycle Consistency라는 제약으로, x를 G로 변환한 뒤 다시 F로 복원했을 때 원본 x와 비슷해야하고, 마찬 가지로 y를 F로 변환했다가 G로 복원했을 때도 원본 y와 비슷해야한다는 것입니다.

x에서 y를 생성하는 제너레이터(G), y에서 x를 생성하는 제너레이터(F)가 있습니다.
그리고 실제 x영상을 넣었을 때, 1이라고 판단하는 디스크리미네이터, y에서 제너레이터 된 영상을 넣으면 0이라고 판단하는 디스크리미네이터(Dx)

반대로, 위 그림 g에 의해서 뭔가 만들어진 영상이 들어가게 되면 0이라고 말해주고,  y 도메인에 어떤 영상이 들어가면 1이라고 말해주는 (Dy)가 있습니다.

Loss(G,F,Dx, Dy)